(this["webpackJsonpblog-site"]=this["webpackJsonpblog-site"]||[]).push([[160],{168:function(e,t,n){"use strict";Object.defineProperty(t,"__esModule",{value:!0}),t.withMDXComponents=void 0;var a=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},r=l(n(1)),o=l(n(173)),i=l(n(7));function l(e){return e&&e.__esModule?e:{default:e}}var s=(0,o.default)({}),c=s.Provider,m=s.Consumer;t.withMDXComponents=function(e){return function(t){var n=t.components,o=function(e,t){var n={};for(var a in e)t.indexOf(a)>=0||Object.prototype.hasOwnProperty.call(e,a)&&(n[a]=e[a]);return n}(t,["components"]);return r.default.createElement(m,null,(function(t){return r.default.createElement(e,a({components:n||t},o))}))}};var d=function(e){var t=e.components,n=e.children;return r.default.createElement(c,{value:t},n)};d.propTypes={components:i.default.object.isRequired,children:i.default.element.isRequired},t.default=d},170:function(e,t,n){"use strict";Object.defineProperty(t,"__esModule",{value:!0});var a=n(171);Object.defineProperty(t,"MDXTag",{enumerable:!0,get:function(){return o(a).default}});var r=n(168);function o(e){return e&&e.__esModule?e:{default:e}}Object.defineProperty(t,"MDXProvider",{enumerable:!0,get:function(){return o(r).default}})},171:function(e,t,n){"use strict";Object.defineProperty(t,"__esModule",{value:!0});var a=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},r=function(){function e(e,t){for(var n=0;n<t.length;n++){var a=t[n];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(e,a.key,a)}}return function(t,n,a){return n&&e(t.prototype,n),a&&e(t,a),t}}(),o=n(1),i=c(o),l=c(n(172)),s=n(168);function c(e){return e&&e.__esModule?e:{default:e}}function m(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}function d(e,t){if(!e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return!t||"object"!==typeof t&&"function"!==typeof t?e:t}var u={inlineCode:"code",wrapper:"div"},p=function(e){function t(){return m(this,t),d(this,(t.__proto__||Object.getPrototypeOf(t)).apply(this,arguments))}return function(e,t){if("function"!==typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function, not "+typeof t);e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,enumerable:!1,writable:!0,configurable:!0}}),t&&(Object.setPrototypeOf?Object.setPrototypeOf(e,t):e.__proto__=t)}(t,e),r(t,[{key:"render",value:function(){var e=this.props,t=e.name,n=e.parentName,r=e.props,o=void 0===r?{}:r,s=e.children,c=e.components,m=void 0===c?{}:c,d=e.Layout,p=e.layoutProps,_=m[n+"."+t]||m[t]||u[t]||t;return d?((0,l.default)(this,d),i.default.createElement(d,a({components:m},p),i.default.createElement(_,o,s))):i.default.createElement(_,o,s)}}]),t}(o.Component);t.default=(0,s.withMDXComponents)(p)},172:function(e,t,n){"use strict";var a={childContextTypes:!0,contextTypes:!0,defaultProps:!0,displayName:!0,getDefaultProps:!0,getDerivedStateFromProps:!0,mixins:!0,propTypes:!0,type:!0},r={name:!0,length:!0,prototype:!0,caller:!0,callee:!0,arguments:!0,arity:!0},o=Object.defineProperty,i=Object.getOwnPropertyNames,l=Object.getOwnPropertySymbols,s=Object.getOwnPropertyDescriptor,c=Object.getPrototypeOf,m=c&&c(Object);e.exports=function e(t,n,d){if("string"!==typeof n){if(m){var u=c(n);u&&u!==m&&e(t,u,d)}var p=i(n);l&&(p=p.concat(l(n)));for(var _=0;_<p.length;++_){var g=p[_];if(!a[g]&&!r[g]&&(!d||!d[g])){var h=s(n,g);try{o(t,g,h)}catch(f){}}}return t}return t}},173:function(e,t,n){"use strict";t.__esModule=!0;var a=o(n(1)),r=o(n(174));function o(e){return e&&e.__esModule?e:{default:e}}t.default=a.default.createContext||r.default,e.exports=t.default},174:function(e,t,n){"use strict";t.__esModule=!0;var a=n(1),r=(i(a),i(n(7))),o=i(n(175));i(n(176));function i(e){return e&&e.__esModule?e:{default:e}}function l(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}function s(e,t){if(!e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return!t||"object"!==typeof t&&"function"!==typeof t?e:t}function c(e,t){if("function"!==typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function, not "+typeof t);e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,enumerable:!1,writable:!0,configurable:!0}}),t&&(Object.setPrototypeOf?Object.setPrototypeOf(e,t):e.__proto__=t)}var m=1073741823;function d(e){var t=[];return{on:function(e){t.push(e)},off:function(e){t=t.filter((function(t){return t!==e}))},get:function(){return e},set:function(n,a){e=n,t.forEach((function(t){return t(e,a)}))}}}t.default=function(e,t){var n,i,u="__create-react-context-"+(0,o.default)()+"__",p=function(e){function n(){var t,a;l(this,n);for(var r=arguments.length,o=Array(r),i=0;i<r;i++)o[i]=arguments[i];return t=a=s(this,e.call.apply(e,[this].concat(o))),a.emitter=d(a.props.value),s(a,t)}return c(n,e),n.prototype.getChildContext=function(){var e;return(e={})[u]=this.emitter,e},n.prototype.componentWillReceiveProps=function(e){if(this.props.value!==e.value){var n=this.props.value,a=e.value,r=void 0;((o=n)===(i=a)?0!==o||1/o===1/i:o!==o&&i!==i)?r=0:(r="function"===typeof t?t(n,a):m,0!==(r|=0)&&this.emitter.set(e.value,r))}var o,i},n.prototype.render=function(){return this.props.children},n}(a.Component);p.childContextTypes=((n={})[u]=r.default.object.isRequired,n);var _=function(t){function n(){var e,a;l(this,n);for(var r=arguments.length,o=Array(r),i=0;i<r;i++)o[i]=arguments[i];return e=a=s(this,t.call.apply(t,[this].concat(o))),a.state={value:a.getValue()},a.onUpdate=function(e,t){0!==((0|a.observedBits)&t)&&a.setState({value:a.getValue()})},s(a,e)}return c(n,t),n.prototype.componentWillReceiveProps=function(e){var t=e.observedBits;this.observedBits=void 0===t||null===t?m:t},n.prototype.componentDidMount=function(){this.context[u]&&this.context[u].on(this.onUpdate);var e=this.props.observedBits;this.observedBits=void 0===e||null===e?m:e},n.prototype.componentWillUnmount=function(){this.context[u]&&this.context[u].off(this.onUpdate)},n.prototype.getValue=function(){return this.context[u]?this.context[u].get():e},n.prototype.render=function(){return(e=this.props.children,Array.isArray(e)?e[0]:e)(this.state.value);var e},n}(a.Component);return _.contextTypes=((i={})[u]=r.default.object,i),{Provider:p,Consumer:_}},e.exports=t.default},175:function(e,t,n){"use strict";(function(t){var n="__global_unique_id__";e.exports=function(){return t[n]=(t[n]||0)+1}}).call(this,n(63))},176:function(e,t,n){"use strict";var a=n(177);e.exports=a},177:function(e,t,n){"use strict";function a(e){return function(){return e}}var r=function(){};r.thatReturns=a,r.thatReturnsFalse=a(!1),r.thatReturnsTrue=a(!0),r.thatReturnsNull=a(null),r.thatReturnsThis=function(){return this},r.thatReturnsArgument=function(e){return e},e.exports=r},179:function(e,t,n){"use strict";function a(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}n.d(t,"a",(function(){return a}))},229:function(e,t,n){"use strict";n.r(t),n.d(t,"staticSiteSetup",(function(){return m})),n.d(t,"cloudFrontSetup",(function(){return d})),n.d(t,"Repo",(function(){return u})),n.d(t,"Post1",(function(){return p})),n.d(t,"clientSideRoute",(function(){return _})),n.d(t,"goodExp",(function(){return g})),n.d(t,"prodBuild",(function(){return h})),n.d(t,"gaTerraform",(function(){return f}));var a=n(179),r=n(1),o=n.n(r),i=n(170),l=n(5),s=n(47),c=["components"],m="https://docs.aws.amazon.com/AmazonS3/latest/userguide/HostingWebsiteOnS3Setup.html",d="https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/",u="https://github.com/arthurdayton116/blog-site",p="https://arthurdayton.com/post/1/",_="https://create-react-app.dev/docs/deployment#serving-apps-with-client-side-routing",g="https://wolovim.medium.com/deploying-create-react-app-to-s3-or-cloudfront-48dae4ce0af",h="https://create-react-app.dev/docs/production-build",f="https://github.com/hashicorp/setup-terraform";t.default=function(e){var t=e.components,n=Object(a.a)(e,c);return o.a.createElement(i.MDXTag,{name:"wrapper",components:t},o.a.createElement(s.a,null,o.a.createElement("meta",{property:"og:type",content:"article"}),o.a.createElement("meta",{name:"title",property:"og:title",content:"Serverless Web Application Deployement on AWS"}),o.a.createElement("meta",{property:"og:url",content:"https://arthurdayton.com/post/6/"}),o.a.createElement("meta",{name:"image",property:"og:image",content:"%PUBLIC_URL%/images/6/preview.png"}),o.a.createElement("meta",{name:"description",property:"og:description",content:"This post shows the code for deploying a serverless application to AWS using Terraform, React, GraphQL and GitHub Actions."}),o.a.createElement("meta",{name:"author",property:"article:author",content:"Arthur Dayton"}),o.a.createElement("meta",{name:"published_time",property:"article:published_time",content:"2022-02-16"}),o.a.createElement("meta",{property:"article:tag",content:"Terraform"}),o.a.createElement("meta",{property:"article:tag",content:"AWS"}),o.a.createElement("meta",{property:"article:tag",content:"React"}),o.a.createElement("meta",{property:"article:tag",content:"Cloudfront"}),o.a.createElement("meta",{property:"article:tag",content:"Route53"}),o.a.createElement("meta",{property:"article:tag",content:"GraphQL"}),o.a.createElement("meta",{property:"article:tag",content:"ACM"}),o.a.createElement("meta",{property:"article:tag",content:"GitHub Actions"})),o.a.createElement(i.MDXTag,{name:"h4",components:t},"Using GitHub Actions to continuously deploy a Serverless blog site"),o.a.createElement(i.MDXTag,{name:"p",components:t},"In this post I am going to cover how to use ",o.a.createElement("a",{href:"https://docs.github.com/en/actions",target:"_blank"},"GitHub Actions")," to continuously build and deploy a serverless web application (this site) using ",o.a.createElement("a",{href:"https://www.terraform.io/",target:"_blank"},"Terraform"),", ",o.a.createElement("a",{href:"https://reactjs.org/",target:"_blank"},"React"),", ",o.a.createElement("a",{href:"https://graphql.org/",target:"_blank"},"GraphQL"),", and several AWS services including ",o.a.createElement("a",{href:"https://aws.amazon.com/lambda/",target:"_blank"},"Lambda"),", ",o.a.createElement("a",{href:"https://aws.amazon.com/api-gateway/",target:"_blank"},"API Gateway"),", ",o.a.createElement("a",{href:"https://aws.amazon.com/s3/",target:"_blank"},"S3"),", ",o.a.createElement("a",{href:"https://aws.amazon.com/sns/",target:"_blank"},"SNS"),", ",o.a.createElement("a",{href:"https://aws.amazon.com/route53/",target:"_blank"},"Route53"),", ",o.a.createElement("a",{href:"https://aws.amazon.com/certificate-manager/",target:"_blank"},"Certificate Manager")," and ",o.a.createElement("a",{href:"https://aws.amazon.com/cloudfront/",target:"_blank"},"CloudFront"),"."),o.a.createElement("br",null),o.a.createElement("details",{open:!0,style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Diagram of what I am implementing:")),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/ArchitectureDiagram.png"})),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"To set this up yourself you need an ",o.a.createElement("a",{href:"https://aws.amazon.com/account/",target:"_blank"},"AWS account"),", a ",o.a.createElement("a",{href:"https://cloud.hashicorp.com/products/terraform",target:"_blank"},"Terraform Cloud account"),", a ",o.a.createElement("a",{href:"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-register.html",target:"_blank"},"custom domain"),", basic React skills, basic Terraform skills, a working knowledge of GitHub Actions and of course the requisite amount of OCD needed to figure out the stuff I almost certainly left out (I wouldn't want to deny you the sweet pain of experience)."),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"I started with the ",o.a.createElement("a",{href:"https://create-react-app.dev/",target:"_blank"},"Create React App")," and built off of it ",o.a.createElement("a",{href:"https://arthurdayton.com/post/1/",target:"_blank"},"How to set up a Git Hub Pages Blog Site Using React and MDX"),'.  The approach for using S3 to serve the static site assets is essentially the same as using GitHub pages but when you start to think about putting an API on the back end I think it\'s "easier" to use AWS.'),o.a.createElement("br",null),o.a.createElement("details",{open:!0,style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"A little background reading from around the internet:")),o.a.createElement("br",null),o.a.createElement("br",null),o.a.createElement(l.g,{p:4,href:m,target:"_blank"},"S3 Static Site Setup"),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"S3 (Simple Storage Service) is definitely the ",o.a.createElement("a",{href:"https://en.wikipedia.org/wiki/Amazon_S3",target:"_blank"},"the OG of AWS")," .  It's cheap (It currrently costs me less than 5 cents a month), easy to use(",o.a.createElement("a",{href:"https://threatpost.com/sega-security-aws-s3-exposed-steam/177352/",target:"_blank"},"to easy?"),"), and pretty seamlessly integrates with lots of other AWS resources, such as Cloudfront."),o.a.createElement("br",null),o.a.createElement(l.g,{p:4,href:d,target:"_blank"},"CloudFront Setup"),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"Cloudfront is a CDN which allows users to cache content around the world and automatically integrates with S3 and Route53 so we can easily map our domain to our content."),o.a.createElement("br",null),o.a.createElement(l.g,{p:4,href:g,target:"_blank"},"This post does a great job of explaining how to integrate S3 and Cloudfront"),o.a.createElement("br",null)),o.a.createElement("br",null),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h2",null,"Building out components of architecture diagram")),o.a.createElement(i.MDXTag,{name:"p",components:t},"To build out my architecture diagram above I use Terraform to define my AWS resources, the AWS CLI to push my React code to my S3 bucket, and a GitHub Actions pipeline to deploy whenever I push changes to the main branch of my repository.  My API is Apollo GraphQL (",o.a.createElement("a",{href:"https://www.apollographql.com/",target:"_blank"},"\u2764\ufe0f\u200d\ud83d\udd25"),") for getting and submitting comments.  It's running as a Lambda function (",o.a.createElement("a",{href:"https://www.apollographql.com/docs/apollo-server/deployment/lambda/",target:"_blank"},"\ud83e\udd2f"),") and using DynamoDB as a data store so that this site is essentially free to deploy and will autoscale to any degree of usage."),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"I could have easily used all AWS tools to do this, but I think there is good reason to stick with some tools that are Cloud agnostic as it becomes clearer every day that the enterprise cloud provider battle is going to work out like the enterprise database or development language battles (everybody is going to have pretty much everything)."),o.a.createElement("br",null),o.a.createElement(l.g,{p:4,href:u,target:"_blank"},"Code Here"),o.a.createElement("br",null),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("h2",{style:{display:"inline"}},"Hosted Zone"),o.a.createElement(i.MDXTag,{name:"p",components:t},"If I want to reach the world then I'm going to need a domain and it will need to support SSL/TLS certificates so I'm using Route53 and ACM (Amazon Certificate Manager) to purchase and renew both.  My hosted zone in Route53 will route traffic to my Cloudfront distributions for my React site and my GraphQL endpoint.  I will need to create those Cloudfront distributions of course, which I show below. As I go along, I will be creating Terraform files for the creation of all resources so that I can easily create and destroy on demand as well as make the process of deploying my site automated and reusable.")),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Basic Terraform code looks like this:")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-json",metaString:""}},'// hosted zone\nresource "aws_route53_zone" "main" {\n  name = local.bucket_name\n}\n\n// gmail record\nresource "aws_route53_record" "gmail_mx" {\n  zone_id = aws_route53_zone.main.zone_id\n  name    = local.bucket_name\n  type    = "MX"\n\n  records = [\n    "1  ASPMX.L.GOOGLE.COM",\n    "5  ALT1.ASPMX.L.GOOGLE.COM",\n    "5  ALT2.ASPMX.L.GOOGLE.COM",\n    "10 ALT3.ASPMX.L.GOOGLE.COM",\n    "10 ALT4.ASPMX.L.GOOGLE.COM",\n  ]\n\n  ttl = "300"\n}\n'))),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"The most important thing to remember, especially  if you are switching what your domain points at, is that when you are sure it's not DNS it's probably DNS."),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows my hosted zone in the AWS Console:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/hostedzone.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"These are the records pointing to my cloudfront distributions:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/hostedzone2.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows the record detail and how to point to a Cloudfront distribution (I use Terrraform to create these when I deploy to Cloudfront below):"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/hzrecord.png"}),o.a.createElement("br",null),o.a.createElement("br",null)),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("h2",{style:{display:"inline"}},"Certificate"),o.a.createElement(i.MDXTag,{name:"p",components:t},"Using ACM you can create a certificate for your domain and have it automatically validate by creating records in your hosted zone")),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows the certificate status and domain validation status in the ACM panel:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/acm2.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows the records created by the validation process (we can use Terraform for this as well):"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/certrecord.png"}),o.a.createElement("br",null),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Terraform code:")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-json",metaString:""}},'//domain certificate\nresource "aws_acm_certificate" "a" {\n  domain_name               = local.bucket_name\n  subject_alternative_names = ["www.${local.bucket_name}"]\n  validation_method         = "DNS"\n}\n\n// validate that we have control over domain so our certificate is trusted\nresource "aws_acm_certificate_validation" "example" {\n  certificate_arn         = aws_acm_certificate.a.arn\n  // loop route records which are the domain name and subject_alternative_names from aws_acm_certificate resource\n  validation_record_fqdns = [for record in aws_route53_record.example : record.fqdn]\n}\n\n\nresource "aws_route53_record" "example" {\n  for_each = {\n    for dvo in aws_acm_certificate.a.domain_validation_options : dvo.domain_name => {\n      name    = dvo.resource_record_name\n      record  = dvo.resource_record_value\n      type    = dvo.resource_record_type\n      zone_id = aws_route53_zone.main.zone_id\n    }\n  }\n\n  allow_overwrite = true\n  name            = each.value.name\n  records         = [each.value.record]\n  ttl             = 60\n  type            = each.value.type\n  zone_id         = each.value.zone_id\n}\n\n// graphql certificate\nresource "aws_acm_certificate" "graphql" {\n  domain_name               = local.bucket_name\n  subject_alternative_names = ["graphql.${local.bucket_name}"]\n  validation_method         = "DNS"\n}\n\nresource "aws_acm_certificate_validation" "graphql" {\n  certificate_arn         = aws_acm_certificate.graphql.arn\n  validation_record_fqdns = [for record in aws_route53_record.graphql : record.fqdn]\n}\n\n\nresource "aws_route53_record" "graphql" {\n  for_each = {\n    for dvo in aws_acm_certificate.graphql.domain_validation_options : dvo.domain_name => {\n      name    = dvo.resource_record_name\n      record  = dvo.resource_record_value\n      type    = dvo.resource_record_type\n      zone_id = aws_route53_zone.main.zone_id\n    }\n  }\n\n  allow_overwrite = true\n  name            = each.value.name\n  records         = [each.value.record]\n  ttl             = 60\n  type            = each.value.type\n  zone_id         = each.value.zone_id\n}\n')))),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("h2",{style:{display:"inline"}},"Cloudfront"),o.a.createElement(i.MDXTag,{name:"p",components:t},"After creating a Cloudfront distribution for my S3 bucket, that I set as an origin, I can point the name records in Route53 at Cloudfront which I showed in the Hosted Zone section above.  As with everything else we can automate and manage these with Terraform.")),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows my distribution for site assets:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/cloudfront.png"}),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/cloudfront2.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows the configured S3 bucket origin where my React build artifacts are pushed from the GitHub Actions pipeline that runs when I commit to my repository:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/cloudfront3.png"}),o.a.createElement("br",null),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Terraform code:")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-json",metaString:""}},'locals {\n  s3_origin_id = "${local.resource_prefix}_${local.bucket_name}_a"\n}\n\nresource "aws_cloudfront_distribution" "s3_distribution_a" {\n  origin {\n    domain_name = local.s3_web_endpoint\n    origin_id   = local.s3_origin_id\n\n    // https://github.com/hashicorp/terraform-provider-aws/issues/7847\n    custom_origin_config {\n      http_port              = "80"\n      https_port             = "443"\n      origin_protocol_policy = "http-only"\n      origin_ssl_protocols   = ["TLSv1", "TLSv1.1", "TLSv1.2"]\n    }\n  }\n\n  enabled         = true\n  is_ipv6_enabled = true\n  //  comment             = ""\n  default_root_object = "index.html"\n\n  logging_config {\n    include_cookies = false\n    bucket          = local.log_bucket_name\n    prefix          = local.resource_prefix\n  }\n\n  aliases = [local.bucket_name, local.alt_name]\n\n  default_cache_behavior {\n    allowed_methods  = ["DELETE", "GET", "HEAD", "OPTIONS", "PATCH", "POST", "PUT"]\n    cached_methods   = ["GET", "HEAD"]\n    target_origin_id = local.s3_origin_id\n\n    forwarded_values {\n      query_string = false\n\n      cookies {\n        forward = "none"\n      }\n    }\n\n    viewer_protocol_policy = "https-only"\n    min_ttl                = 0\n    default_ttl            = 3600\n    max_ttl                = 86400\n  }\n\n  price_class = "PriceClass_All"\n\n  restrictions {\n\n    geo_restriction {\n      restriction_type = "none"\n    }\n  }\n\n  tags = merge(\n    local.base_tags,\n    {\n      Name = "${local.resource_prefix}-${local.bucket_name}"\n    },\n  )\n\n  viewer_certificate {\n    acm_certificate_arn = local.cert_arn\n    ssl_support_method  = "sni-only"\n  }\n}\n\n// Create subdomain A record pointing to Cloudfront distribution\nresource "aws_route53_record" "www" {\n  zone_id = local.zone_id\n  name    = "www.${local.bucket_name}"\n  type    = "A"\n\n  alias {\n    name                   = aws_cloudfront_distribution.s3_distribution_a.domain_name\n    zone_id                = aws_cloudfront_distribution.s3_distribution_a.hosted_zone_id\n    evaluate_target_health = false\n  }\n}\n\n// Create domain A record pointing to Cloudfront distribution\nresource "aws_route53_record" "a" {\n  zone_id = local.zone_id\n  name    = local.bucket_name\n  type    = "A"\n\n  alias {\n    name                   = aws_cloudfront_distribution.s3_distribution_a.domain_name\n    zone_id                = aws_cloudfront_distribution.s3_distribution_a.hosted_zone_id\n    evaluate_target_health = false\n  }\n}\n')))),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("h2",{style:{display:"inline"}},"S3 Buckets"),o.a.createElement(i.MDXTag,{name:"p",components:t},"For this site I'm using 2 S3 buckets.  One for the site assets that we will use as a source for our CloudFront distribution and one for logs and Athena query results.")),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows the buckets:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/S3list.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows the site assets from React build:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/S3assets.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This shows relevant properties for site assets bucket:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/S3domain.png"}),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/S3www.png"}),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Terraform code:")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-json",metaString:""}},'// root domain bucket and policy\n\n// Clean up bucket for destroy aws s3 rm s3://bucketname --recursive\nresource "aws_s3_bucket" "a" {\n  bucket = local.bucket_name\n\n  // For a React site the index needs to be error document as well and React needs to handle errors\n  website {\n    index_document = "index.html"\n    error_document = "index.html"\n  }\n\n  logging {\n    target_bucket = aws_s3_bucket.log.id\n    target_prefix = "s3-log/"\n  }\n  force_destroy = true\n  tags = merge(\n    local.base_tags,\n    {\n      Name      = "${local.resource_prefix}-${local.bucket_name}"\n      directory = basename(path.cwd)\n    },\n  )\n}\n\nresource "aws_s3_bucket" "log" {\n  bucket = "logs-${local.bucket_name}"\n\n  force_destroy = true\n\n  grant {\n    type        = "Group"\n    permissions = ["READ_ACP", "WRITE"]\n    uri         = "http://acs.amazonaws.com/groups/s3/LogDelivery"\n  }\n\n  //CloudFront\n  // Permissions required to configure standard logging and to access your log files\n  // https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html\n  grant {\n    id          = "c4c1ede66af53448b93c283ce9448c4ba468c9432aa01d700d3878632f77d2d0"\n    permissions = ["FULL_CONTROL", ]\n    type        = "CanonicalUser"\n  }\n\n  grant {\n    id          = data.aws_canonical_user_id.current_user.id\n    type        = "CanonicalUser"\n    permissions = ["FULL_CONTROL"]\n  }\n\n  tags = merge(\n    local.base_tags,\n    {\n      Name = "${local.resource_prefix}-logs-${local.bucket_name}"\n    },\n  )\n}\n\nresource "aws_s3_bucket_object" "log_query_folder" {\n  bucket = aws_s3_bucket.log.id\n  acl    = "private"\n  key    = "queryResults/"\n  source = "/dev/null"\n}\n// This ensures that bucket content can be read publicly\n// I like setting it up this way so it\'s easier to test changes\n// Check here for different setups  - https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/\n// Policy limits to specific bucket\nresource "aws_s3_bucket_policy" "a" {\n  bucket = aws_s3_bucket.a.id\n\n  policy = jsonencode({\n    Version = "2012-10-17"\n    Id      = "${local.resource_prefix}-${local.bucket_name}-policy"\n    Statement = [\n      {\n        Sid       = "PublicRead"\n        Effect    = "Allow"\n        Principal = "*"\n        Action = [\n          "s3:GetObject",\n          "s3:GetObjectVersion"\n        ]\n        Resource = [\n          aws_s3_bucket.a.arn,\n          "${aws_s3_bucket.a.arn}/*",\n        ]\n      },\n    ]\n  })\n}\n')))),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("h2",{style:{display:"inline"}},"GitHub Actions"),o.a.createElement(i.MDXTag,{name:"p",components:t},"For my continuous integration I am using GitHub.  Right now I am using the main branch and not a PR flow because it's just me and I can make it work with local dev and GitHub actions.  In a context any larger than myself I would set up a separate dev domain either within a VPC or locked down by IP address.  GitHub Actions is pretty awesome and it's been exciting watching it mature towards being an Enterprise ready tool.  Care and feeding of architecture is painful and having this capability delivered right to my GitHub repository is awesome!  If you've used Azure Devops (lately) then it will look and feel very familiar.")),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h3",null,"Environment"),"\nFirst thing I needed to do was set up an environment in Actions so I can store secrets:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/actionsenv.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h3",null,"Actions Workflow")),o.a.createElement(i.MDXTag,{name:"p",components:t},"Then I can set up the yaml file that will define my workflow that runs whenever I commit code.  GitHub has a default location for the file:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/actionslocation.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"I reference my environment and then I can pull secrets into my build job runs securely:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml1.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"Now I can create all the steps needed to build this application from top to bottom:"),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h4",null,"Set up dynamodb container for automated tests")),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml2.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h4",null,"Check out previous commit so we can see what files have changed and only run certain steps")),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml3.png"}),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml4.png"}),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml5.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h4",null,"Set up Terraform")),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml6.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h4",null,"Run Terraform apply if files have changed and set and environment variables needed for following steps")),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml7.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},o.a.createElement("h4",null,"Build graphql code, zip for Lambda and create Lambda")),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml8.png"}),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"API Gateway Terraform:")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-json",metaString:""}},'# Create an API endpoint for graphql lambda\nresource "aws_api_gateway_rest_api" "gql" {\n  name        = "BlogGraphql"\n  description = "Terraform Serverless GraphQL Example"\n}\n\nresource "aws_api_gateway_account" "gql" {\n  cloudwatch_role_arn = aws_iam_role.cloudwatch.arn\n}\n\nresource "aws_iam_role" "cloudwatch" {\n  name = "${local.resource_prefix}-api_gateway_cloudwatch_global_gql"\n\n  assume_role_policy = jsonencode({\n    Version = "2012-10-17"\n    "Statement" : [\n      {\n        Sid : "",\n        Effect : "Allow",\n        Principal : {\n          Service : "apigateway.amazonaws.com"\n        },\n        Action : "sts:AssumeRole"\n      }\n    ]\n  })\n}\n\nresource "aws_iam_role_policy_attachment" "cloudwatch_gql" {\n  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs"\n  role       = aws_iam_role.cloudwatch.name\n}\n\n// Creates method in api gateway for graphql\n// https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html\nresource "aws_api_gateway_resource" "gql_method" {\n  rest_api_id = aws_api_gateway_rest_api.gql.id\n  parent_id   = aws_api_gateway_rest_api.gql.root_resource_id\n  path_part   = "graphql"\n}\n\nresource "aws_api_gateway_method" "proxy" {\n  rest_api_id   = aws_api_gateway_rest_api.gql.id\n  resource_id   = aws_api_gateway_resource.gql_method.id\n  http_method   = "POST"\n  authorization = "NONE"\n}\n\n// point api to lambda for execution\nresource "aws_api_gateway_integration" "lambda" {\n  rest_api_id = aws_api_gateway_rest_api.gql.id\n  resource_id = aws_api_gateway_method.proxy.resource_id\n  http_method = aws_api_gateway_method.proxy.http_method\n\n  integration_http_method = "POST"\n  type                    = "AWS_PROXY"\n  uri                     = aws_lambda_function.gql_lambda.invoke_arn\n}\n\nresource "aws_api_gateway_integration" "lambda_root" {\n  rest_api_id = aws_api_gateway_rest_api.gql.id\n  resource_id = aws_api_gateway_method.proxy_root.resource_id\n  http_method = aws_api_gateway_method.proxy_root.http_method\n\n  integration_http_method = "POST"\n  type                    = "AWS_PROXY"\n  uri                     = aws_lambda_function.gql_lambda.invoke_arn\n}\n\nresource "aws_api_gateway_deployment" "gql" {\n  depends_on = [\n    aws_api_gateway_integration.lambda,\n    aws_api_gateway_integration.lambda_root,\n  ]\n\n  rest_api_id = aws_api_gateway_rest_api.gql.id\n  stage_name  = local.stage_name\n}\n\nresource "aws_api_gateway_method" "proxy_root" {\n  rest_api_id   = aws_api_gateway_rest_api.gql.id\n  resource_id   = aws_api_gateway_rest_api.gql.root_resource_id\n  http_method   = "ANY"\n  authorization = "NONE"\n}\n\n// Create a custom domain for api\nresource "aws_api_gateway_domain_name" "graphql" {\n  certificate_arn = local.graphql_cert_arn\n  domain_name     = "graphql.${local.bucket_name}"\n}\n\n// This creates an A record in Route 53 for graphql subdomain\nresource "aws_route53_record" "graphql" {\n  name    = aws_api_gateway_domain_name.graphql.domain_name\n  type    = "A"\n  zone_id = local.zone_id\n\n  alias {\n    evaluate_target_health = true\n    name                   = aws_api_gateway_domain_name.graphql.cloudfront_domain_name\n    zone_id                = aws_api_gateway_domain_name.graphql.cloudfront_zone_id\n  }\n}\n\n// this maps the custom domain to the api\nresource "aws_api_gateway_base_path_mapping" "example" {\n  api_id      = aws_api_gateway_rest_api.gql.id\n  stage_name  = local.stage_name\n  domain_name = aws_api_gateway_domain_name.graphql.domain_name\n}\n'))),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Lambda Terraform:")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-json",metaString:""}},'// attach policy to role\nresource "aws_iam_role_policy_attachment" "sns" {\n  role       = aws_iam_role.iam_for_lambda.name\n  policy_arn = aws_iam_policy.gql_sns.arn\n}\n\nresource "aws_iam_role_policy_attachment" "dynamoDb" {\n  role       = aws_iam_role.iam_for_lambda.name\n  policy_arn = aws_iam_policy.gql_dynamoDb.arn\n}\n\nresource "aws_iam_role_policy_attachment" "basic" {\n  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"\n  role       = aws_iam_role.iam_for_lambda.name\n}\n\n// create policy\nresource "aws_iam_policy" "gql_dynamoDb" {\n  name        = "${local.resource_prefix}-gql-dynamodb"\n  description = "Policy for dynamo db access"\n  policy      = data.aws_iam_policy_document.gql_dynamoDb.json\n}\n\n// create policy document\ndata "aws_iam_policy_document" "gql_dynamoDb" {\n  statement {\n    actions = [\n      "dynamodb:BatchGetItem",\n      "dynamodb:GetItem",\n      "dynamodb:Query",\n      "dynamodb:Scan",\n      "dynamodb:BatchWriteItem",\n      "dynamodb:PutItem",\n      "dynamodb:UpdateItem",\n      "dynamodb:DescribeTable"\n    ]\n    effect    = "Allow"\n    resources = [local.dynamo_arn, "${local.dynamo_arn}/index/*"]\n  }\n}\n\n// create policy\nresource "aws_iam_policy" "gql_sns" {\n  name        = "${local.resource_prefix}-gql-sns"\n  description = "Policy for sns publish"\n  policy      = data.aws_iam_policy_document.gql_sns.json\n}\n\ndata "aws_iam_policy_document" "gql_sns" {\n  statement {\n    actions = [\n      "sns:Publish"\n    ]\n    effect    = "Allow"\n    resources = [local.sns_arn]\n  }\n}\n\n\nresource "aws_iam_role" "iam_for_lambda" {\n  name = "${local.resource_prefix}_iam_for_gql_lambda"\n\n  assume_role_policy = jsonencode({\n    Version = "2012-10-17"\n    Statement = [\n      {\n        Action = "sts:AssumeRole"\n        Effect = "Allow"\n        Sid    = ""\n        Principal = {\n          Service = "lambda.amazonaws.com"\n        }\n      },\n    ]\n    }\n  )\n\n}\n\n// create lambda function\nresource "aws_lambda_function" "gql_lambda" {\n  filename      = "./function/function.zip"\n  function_name = "${local.resource_prefix}_simple_gql_lambda_v"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = "graphql.graphqlHandler"\n\n  # The filebase64sha256() function is available in Terraform 0.11.12 and later\n  # For Terraform 0.11.11 and earlier, use the base64sha256() function and the file() function:\n  # source_code_hash = "${base64sha256(file("lambda_function_payload.zip"))}"\n  source_code_hash = filebase64sha256("./function/function.zip")\n\n  runtime = "nodejs14.x"\n\n  environment {\n    variables = {\n      ddb_table_name     = local.dynamo_table_name\n      ddb_hash_key       = local.dynamo_hash_key\n      ddb_region         = local.region\n      GRAPHQL_ENDPOINT   = aws_api_gateway_domain_name.graphql.domain_name\n      SNS_ARN            = local.sns_arn\n      OKTA_CLIENT_ID     = var.okta_client_id\n      OKTA_CLIENT_SECRET = var.okta_client_secret\n      OKTA_DOMAIN        = var.okta_domain\n      OKTA_ISSUER_SUFFIX = var.okta_issuer_suffix\n      OKTA_ISSUER        = local.OKTA_ISSUER\n      OKTA_AUDIENCE      = var.okta_audience\n      APP_BASE_PORT      = 4000\n\n    }\n  }\n\n  tags = merge(\n    local.base_tags,\n    {\n      Name      = "${local.resource_prefix}_simple_gql_lambda_v"\n      directory = basename(path.cwd)\n    },\n  )\n}\n\nresource "aws_lambda_permission" "apigw" {\n  statement_id  = "AllowAPIGatewayInvoke"\n  action        = "lambda:InvokeFunction"\n  function_name = aws_lambda_function.gql_lambda.function_name\n  principal     = "apigateway.amazonaws.com"\n\n  # The "/*/*" portion grants access from any method on any resource\n  # within the API Gateway REST API.\n  source_arn = "${aws_api_gateway_rest_api.gql.execution_arn}/*/*"\n}\n')))),o.a.createElement("br",null),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("h2",{style:{display:"inline"}},"Testing React and GraphQL"),o.a.createElement(i.MDXTag,{name:"p",components:t},"We need to build automated testing into our code, even if you start small.  My favorite testing tool is ",o.a.createElement("a",{href:"https://www.cypress.io/ ",target:"_blank"},"Cypress.io")," and I like to use a docker-compose file to set up a local development environment of networked containers that have my local code mounted as directories.  This allows me to continuously build and test with a stable environment that should be the same no matter where I run it.  Cypress provides both a desktop tool, where you can watch tests run in real time and observe the state of the browser as it was at any time during the test, and a command line utility that easily integrates into your favorite pipleline tool.")),o.a.createElement("details",{style:{paddingLeft:n.theme.detail.paddingLeft}},o.a.createElement("summary",null,o.a.createElement("strong",null,"Compose File")),o.a.createElement(i.MDXTag,{name:"pre",components:t},o.a.createElement(i.MDXTag,{name:"code",components:t,parentName:"pre",props:{className:"language-yaml",metaString:""}},'    version: "3.9"  # optional since v1.27.0\n    services:\n    # UI container - uses command from package.json file to start\n    # need to install nodemon\n    react:\n    image: node:16\n    command: /bin/bash -c "ls & npm install nodemon -g && yarn start:nodemon"\n    ports:\n    - "3001:3001"\n    volumes:\n    - ./ui:/src\n    working_dir: /src\n    # This variable is used in App.js, if it exists then it points to this endpoint\n    # with docker network the service name (graphql) is all we need to route\n    # ui should be running at http://localhost:3001/\n    environment:\n    DOCKER_GRAPHQL_ENDPOINT: graphql\n\n    dynamodb:\n    image: amazon/dynamodb-local:1.17.0\n    ports:\n    - "8000:8000"\n    # gives container a drive to mount\n    volumes:\n    - ./terraform/terraform_graphql/function/dynamodb:/home/dynamodblocal/data\n    working_dir: /home/dynamodblocal\n    graphql:\n    image: node:16\n    command: /bin/bash -c "ls & npm install nodemon -g && nodemon index.js"\n    depends_on:\n    - dynamodb\n    ports:\n    - "4000:4000"\n    volumes:\n    - ./terraform/terraform_graphql/function/src:/src\n    - $HOME/.aws/credentials:/root/.aws/credentials\n    working_dir: /src\n    # graphql should be running at http://localhost:4000/graphql\n    environment:\n    # This value tells graphql to point at local version of dynamodb if it exists\n    CYPRESS_GRAPHQL: "true"\n    GRAPHQL_PORT: 4000\n    # Tells graphql to ignore the need for authentication\n    JWT_OVERRIDE: "true"\n    # points to service running above\n    DYNAMO_HOST: dynamodb\n'))),o.a.createElement("br",null),o.a.createElement(i.MDXTag,{name:"p",components:t},"Here the pipeline runs Cypress tests that cover ui and graphql"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml9.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This part builds the React project and uploads it to S3 bucket:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml10.png"}),o.a.createElement(i.MDXTag,{name:"p",components:t},"This conditionally updates the Cloudfront distribution if Terraform files have changed:"),o.a.createElement(l.f,{p:4,verticalAlign:"middle",src:"/images/6/yaml11.png"})),o.a.createElement("br",null),o.a.createElement("br",null))}}}]);
//# sourceMappingURL=160.b424bf2f.chunk.js.map